# RL-Traffic-Control

## Traffic Control at Traffic Light Intersection with Reinforcement Learning
### Falbo Andrea 887525 - Tenderini Ruben 879290

## Table of Contents

1. [Objective](#objective)
2. [Contents](#contents)
3. [Tools](#tools)
4. [Codebase](#codebase)
5. [Study](#study)
6. [References](#references)

## Objective

The objective of this project is to compare different reinforcement learning algorithms in controlling traffic flow at a traffic light intersection. We aim to evaluate their performance under various traffic conditions and configurations.

## Contents

- We utilized the Big Intersection as our traffic intersection model.
- Three traffic configurations were considered: low, medium, and high.
- In addition to Fixed-Time Control, we implemented four reinforcement learning algorithms:
  - Q-Learning
  - Deep Q-Learning
  - Sarsa
  - Sarsa Decay
  
  Sarsa Decay is similar to Sarsa, but it utilizes epsilon greedy to decay epsilon. Notably, it was not implemented in the Sumo-RL repository.

## Tools

The following tools were used in this project:

- Sumo
- Sumo-RL
- Stable Baselines 3
- 2WSI-RL
- Deep Q-Learning agent for Traffic Signal Control
- Matplotlib
- Python
- PyCharm
- Github

## Codebase

[Placeholder for codebase description]

## Study

All the theoretical background, study, and experiments conducted are documented in the 'docs' folder in both English (relation.pdf) and Italian (relazione.pdf).

## References

[Placeholder for references]